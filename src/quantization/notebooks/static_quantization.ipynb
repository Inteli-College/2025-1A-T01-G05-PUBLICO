{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62f84e5f",
   "metadata": {},
   "source": [
    "# Static Quantization for Yolo\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a1f691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install libraries\n",
    "%pip install opencv-python ultralytics onnxruntime numpy "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "366cde1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Libraries\n",
    "\n",
    "# Built-in\n",
    "from pathlib import Path\n",
    "\n",
    "# Third-party\n",
    "import cv2\n",
    "import numpy as np\n",
    "from onnxruntime.quantization import quantize_static, CalibrationDataReader, QuantType, QuantFormat\n",
    "from ultralytics import YOLO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fc1b911c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_fp32 = Path('models/best_fp32_preprocessed.onnx')\n",
    "model_quant = Path('models/static_int8_quant.onnx')\n",
    "calibration_images_path = Path(\"tcc-1/valid/images/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ed256f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Static Quantization for YoloV8\n",
    "class ImageCalibrationDataReader(CalibrationDataReader):\n",
    "    def __init__(self, image_paths):\n",
    "        self.image_paths = image_paths\n",
    "        self.idx = 0\n",
    "        self.input_name = \"images\"\n",
    "\n",
    "    def preprocess(self, frame):\n",
    "        frame = cv2.imread(frame)\n",
    "        X = cv2.resize(frame, (640, 640))\n",
    "        image_data = np.array(X).astype(np.float32) / 255.0\n",
    "        image_data = np.transpose(image_data, (2, 0, 1))\n",
    "        image_data = np.expand_dims(image_data, axis=0)\n",
    "        return image_data\n",
    "\n",
    "    def get_next(self):\n",
    "        if self.idx >= len(self.image_paths):\n",
    "            return None\n",
    "\n",
    "        image_path = self.image_paths[self.idx]\n",
    "        input_data = self.preprocess(image_path)\n",
    "        self.idx += 1\n",
    "        return {self.input_name: input_data}\n",
    "\n",
    "\n",
    "calibration_data_reader = ImageCalibrationDataReader(list(calibration_images_path.glob(\"*.jpg\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "14f784fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "quantize_static(model_fp32,\n",
    "                model_quant,\n",
    "                weight_type=QuantType.QInt8,\n",
    "                activation_type=QuantType.QUInt8,\n",
    "                calibration_data_reader=calibration_data_reader,\n",
    "                quant_format=QuantFormat.QDQ,\n",
    "                nodes_to_exclude=['/model.22/Concat_3', '/model.22/Split', '/model.22/Sigmoid'\n",
    "                                '/model.22/dfl/Reshape', '/model.22/dfl/Transpose', '/model.22/dfl/Softmax', \n",
    "                                '/model.22/dfl/conv/Conv', '/model.22/dfl/Reshape_1', '/model.22/Slice_1',\n",
    "                                '/model.22/Slice', '/model.22/Add_1', '/model.22/Sub', '/model.22/Div_1',\n",
    "                                '/model.22/Concat_4', '/model.22/Mul_2', '/model.22/Concat_5'],\n",
    "                per_channel=False,\n",
    "                reduce_range=True,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b9dc50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = YOLO(model_quant, task=\"detect\")\n",
    "metrics = model.val(data=\"tcc-1/data.yaml\", split='val')\n",
    "print(metrics)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
